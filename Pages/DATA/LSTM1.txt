import numpy as np
import matplotlib.pyplot as plt
    
class LSTMLayer:
    def __init__(self, n_upper, n):
        self.w = np.random.randn(4, n_upper, n) / np.sqrt(n_upper)
        self.v = np.random.randn(4, n, n) / np.sqrt(n)
        self.b = np.zeros((4, n))
    
    def forward(self, x, y_prev, c_prev):
        u = np.matmul(x, self.w) + np.matmul(y_prev, self.v) + self.b.reshape(4, 1, -1)
        
        a0 = sigmoid(u[0]) # 망각게이트
        a1 = sigmoid(u[1]) # 입력게이드
        a2 = np.tanh(u[2]) # 새로운 기억
        a3 = sigmoid(u[3]) # 출력게이트
        
        self.gates = np.stack((a0, a1, a2, a3))
        
        self.c = a0 * c_prev + a1 * a2 # 기억셀
        self.y = a3 * np.tanh(self.c) # 출력
        
    def backward(self, x, y, c, y_prev, c_prev, gates, grad_y, grad_c):
        a0, a1, a2, a3 = gates
        tanh_c = np.tanh(c)
        r = grad_c + (grad_y * a3) * (1-tanh_c ** 2)
        
        # Each Delta
        delta_a0 = r * c_prev * a0 * (1 - a0)
        delta_a1 = r * a2 * a1 * (1 - a0)
        delta_a2 = r * a1 * (1 - a2 ** 2)
        delta_a3 = grad_y * tanh_c * a3 * (1 - a3)
        
        deltas = np.stack((delta_a0, delta_a1, delta_a2, delta_a3))
        
        # Each Parameters Gradients
        self.grad_w += np.matmul(x.T, deltas)
        self.grad_v += np.matmul(y_prev.T, deltas)
        self.grad_b += np.sum(deltas, axis = 1)
        
        # Gradient of x
        grad_x = np.matmul(deltas, self.w.transpose(0, 2, 1))
        self.grad_x = np.sum(grad_x, axis = 0)
        
        # Gradient of y_prev
        grad_y_prev = np.matmul(deltas, self.v.transpose(0, 2, 1))
        self.grad_y_prev = np.sum(grad_y_prev, axis = 0)
        
        # Gradient of c_prev
        self.grad_c_prev = r * a0
        
    def reset_sum_grad(self):
        self.grad_w = np.zeros_like(self.w)
        self.grad_v = np.zeros_like(self.v)
        self.grad_b = np.zeros_like(self.b)
    
    def update(self, eta):
        self.w -= eta * self.grad_w
        self.v -= eta * self.grad_v
        self.b -= eta * self.grad_b

#전결합 출력층
class OutputLayer:
    def __init__(self, n_upper, n):
        # 자비에르 초기화 기반의 초깃값
        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)
        self.b = np.zeros(n)
    
    def forward(self, x):
        self.x = x
        u = np.dot(x, self.w) + self.b
        self.y = u
        
    def backward(self, t):
        delta = self.y - t
        self.grad_w = np.dot(self.x.T, delta)
        self.grad_b = np.sum(delta, axis = 0)
        self.grad_x = np.dot(delta, self.w.T)
    
    def update(self, eta):
        self.w -= eta * self.grad_w
        self.b -= eta * self.grad_b

def sigmoid(x):
    return 1/(1 + np.exp(-x))
        
def train(x_mb, t_mb):
    # 순전파 LSTM 층
    y_rnn = np.zeros((len(x_mb), n_time + 1, n_mid))
    c_rnn = np.zeros((len(x_mb), n_time + 1, n_mid))
    gates_rnn = np.zeros((4, len(x_mb), n_time, n_mid))
    
    y_prev = y_rnn[:, 0, :]
    c_prev = c_rnn[:, 0, :]
    
    for i in range(n_time):
        x = x_mb[:, i, :]
        lstm_layer.forward(x, y_prev, c_prev)
        
        y = lstm_layer.y
        y_rnn[:, i+1, :] = y
        y_prev = y
        
        c = lstm_layer.c
        c_rnn[:, i+1, :] = c
        c_prev = c
        
        gates = lstm_layer.gates
        gates_rnn[:, :, i, :] = gates

    output_layer.forward(y)
    output_layer.backward(t_mb)
    grad_y = output_layer.grad_x
    grad_c = np.zeros_like(lstm_layer.c)
    
    # 역전파 LSTM층
    lstm_layer.reset_sum_grad()
    
    for i in reversed(range(n_time)):
        x = x_mb[:, i, :]
        y = y_rnn[:, i+1, :]
        c = c_rnn[:, i+1, :]
        y_prev = y_rnn[:, i, :]
        c_prev = c_rnn[:, i, :]
        gates = gates_rnn[:, :, i, :]
        
        lstm_layer.backward(x, y, c, y_prev, c_prev, gates, grad_y, grad_c)
        grad_y = lstm_layer.grad_y_prev
        grad_c = lstm_layer.grad_c_prev
    
    lstm_layer.update(eta)
    output_layer.update(eta)
    
def predict(x_mb):
    y_prev = np.zeros((len(x_mb), n_mid))
    c_prev = np.zeros((len(x_mb), n_mid))
    for i in range(n_time):
        x = x_mb[:, i, :]
        lstm_layer.forward(x, y_prev, c_prev)
        y = lstm_layer.y
        y_prev = y
        c = lstm_layer.c
        c_prev = c
        
    output_layer.forward(y)
    return output_layer.y

def get_error(x, t):
    y = predict(x)
    return 1.0 / 2.0 * np.sum(np.square(y - t))

def make_dataset(n_time, n_in, n_mid, n_out):
    # DataSets
    sin_x = np.linspace(-2 * np.pi, 2 * np.pi)
    sin_y = np.sin(sin_x) + 0.1 * np.random.randn(len(sin_x))
    n_sample = len(sin_x) - n_time
    
    # 3-Dimension
    input_data = np.zeros((n_sample, n_time, n_in))
    # 2-Dimension
    correct_data = np.zeros((n_sample, n_out))

    for i in range(0, n_sample):
        # n_time data input
        input_data[i] = sin_y[i:i + n_time].reshape(-1,1)
        # one data ouput after i
        correct_data[i] = sin_y[i + n_time:i + n_time + 1]
    return [input_data, correct_data]

def data_setting(dat):
    return dat

def csv_load(file):
    x = None
    y = None
    return [x, y]

# Term
n_time = 10
# The Number of Input Node
n_in = 1
# Hidden Layer
n_mid = 60
# The Number of Output Node
n_out = 1


# 학습률
eta = 0.01
# 연산(학습) 수
epochs = 100
# 몇개의 데이터 텀
batch_size = 8
# 간격
interval = 10

data = make_dataset(n_time, n_in, n_mid, n_out)
input_data = data[0]
correct_data = data[1]

lstm_layer = LSTMLayer(n_in, n_mid)
output_layer = OutputLayer(n_mid, n_out)

error_record = []
n_batch = len(input_data) // batch_size

for i in range(epochs):
    index_random = np.arange(len(input_data))
    np.random.shuffle(index_random)
    
    for j in range(n_batch):
        mb_index = index_random[j * batch_size : (j+1) * batch_size]
        x_mb = input_data[mb_index, :]
        t_mb = correct_data[mb_index, :]
        train(x_mb, t_mb)
        
    error = get_error(input_data, correct_data)
    error_record.append(error)
    
    if i % interval == 0:
        print("Epochs:" + str(i+1) + "/" + str(epochs), "Error:" + str(error))
        predicted = input_data[0].reshape(-1).tolist()
        for i in range(n_sample):
            x =  np.array(predicted[-n_time:]).reshape(1, n_time, 1)
            y = predict(x)
            predicted.append(float(y[0, 0]))
        
        #plt.plot(range(len(sin_y)), sin_y.tolist(), label = "CORRECT")
        #plt.plot(range(len(predicted)), predicted, label = "PREDICTED")
        #plt.legend()
        #plt.show()

print()        
print(sin_y[0])
print((predicted[0]))
plt.plot(range(1, len(error_record) + 1), error_record)
plt.xlabel("EPOCHS")
plt.ylabel("ERROR")
plt.show()