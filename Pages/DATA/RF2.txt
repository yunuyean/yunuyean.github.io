import csv
import pandas as pd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
%matplotlib inline

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn import metrics

def graph_compare(y_test, x_test, forest):
    #compare Answer Predict
    amountofData = 100
    answer = pd.DataFrame((y_test[:amountofData]).reset_index())
    del answer["index"]
    plt.rcParams["figure.figsize"] = (15,8)
    plt.plot(answer, label="answer")
    plt.plot(forest.predict(x_test[:amountofData]), label="predict", alpha = 0.5)
    a = list(map(int, range(answer.__len__())))
    plt.xlabel("Answer/Predict")
    #plt.scatter(a, answer, alpha = 0.5, color = "black")
    #plt.scatter(a,forest.predict(x_test[:amountofData]), alpha = 0.5, color = "red")
    plt.legend()
    plt.show()

def graph_importance(x, forest):
    #Features Importance
    colors = ['black','dimgray','dimgrey','darkgray','silver','lightgrey']
    n_features = x.shape[1]
    #plt.subplot(2, 1, 2)
    plt.rcParams["figure.figsize"] = (15,8)
    plt.barh(np.arange(n_features), sorted(forest.feature_importances_), align="center", height = 0.5, color = colors)
    plt.yticks(np.arange(n_features), x.columns)
    plt.xlabel("Random Forest Feature Importance")
    plt.ylabel("Features")
    plt.ylim(-1, n_features)
    plt.show()
    
def main():

    filename = 'DATA.csv'
    
    new_data = pd.read_csv(filename, encoding='cp949')            
    print("FILE Finding -------------------- [COMPLETED]")
    new_data = new_data.fillna(0)
    print("NaN DATA CONVERTED TO 0 --------- [COMPLETED]")
    data_features = new_data.columns 
    print("FINDING DATA FEATURES ----------- [COMPLETED]")
    print("---------------------------------------------")

    for i in range(0, len(data_features)):
        print("  Feature",i, ':',data_features[i])
    print("---------------------------------------------")
    #feature_size = (int)(input("ENTER SIZE OF FEATURES FOR LEARNING:"))
    feature_size = 9
    features = []

    features = ['TEMP','PRES', 'HUMID','GROTEMP','TEMP5','TEMP10','TEMP20','TEMP30', 'RAIN']
    resultfeat = 'VIS'
    testsize = 0.3

    x = new_data[features]
    y = new_data[resultfeat]
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=testsize)


    nestimators = 100
    randomstate = 0
    maxFeat = len(features)

    forest = RandomForestRegressor(n_estimators=nestimators, max_features=maxFeat,random_state=randomstate, max_depth=100)
    forest.fit(x_train, y_train)
    y_pred = forest.predict(x_test)

    print("RANDOM FOREST MODEL LEARNING ---- [COMPLETED]")
    print("Model Accuracy: ",abs((int)(forest.score(x_test,y_test) * 100)), "%")
    
    graph_compare(y_test, x_test, forest)
    graph_importance(x, forest)
    
    #joblib.dump(forest, 'SavedTEST.pkl')

if __name__ == "__main__":
    main()
    #test()
    
